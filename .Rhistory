inner_join(all_history_model2, by=c("word")) %>% # Merge them together
arrange(-(similarity.x^2 + similarity.y^2)) %>% # sort by decreasing size of the combined similarities
head(200) %>% # Take only the top 100 items
filter(word!="history") %>%
ggplot() + geom_text(aes(x=similarity.x,y=similarity.y,label=word))
all_history = model %>% closest_to("idolatry", n=Inf)
all_history_model2 = model2 %>% closest_to(~ "idolatry", n=Inf)
all_history %>%
inner_join(all_history_model2, by=c("word")) %>% # Merge them together
arrange(-(similarity.x^2 + similarity.y^2)) %>% # sort by decreasing size of the combined similarities
head(200) %>% # Take only the top 100 items
filter(word!="history") %>%
ggplot() + geom_text(aes(x=similarity.x,y=similarity.y,label=word))
all_history = model %>% closest_to("idolatry", n=Inf)
all_history_model2 = model2 %>% closest_to(~ "idolatry", n=Inf)
all_history %>%
inner_join(all_history_model2, by=c("word")) %>% # Merge them together
arrange(-(similarity.x^2 + similarity.y^2)) %>% # sort by decreasing size of the combined similarities
head(100) %>% # Take only the top 100 items
filter(word!="history") %>%
ggplot() + geom_text(aes(x=similarity.x,y=similarity.y,label=word))
all_history = model %>% closest_to("papist", n=Inf)
all_history_model2 = model2 %>% closest_to(~ "papist", n=Inf)
all_history %>%
inner_join(all_history_model2, by=c("word")) %>% # Merge them together
arrange(-(similarity.x^2 + similarity.y^2)) %>% # sort by decreasing size of the combined similarities
head(100) %>% # Take only the top 100 items
filter(word!="history") %>%
ggplot() + geom_text(aes(x=similarity.x,y=similarity.y,label=word))
model = read.vectors("RMP.bin")
model %>%
closest_to(list(~"he" - "she", ~"good" - "bad"), n = 500, merge.method = "magnitude") %>%
spread(comparison,similarity) %>%
ggplot() +
geom_text() +
aes(x=`he - she`, y=`good - bad`, label=word)
model %>%
closest_to(list(~"man" - "woman", ~"good" - "bad"), n = 500, merge.method = "magnitude") %>%
# ebb: This is saying, make a vector showing the distance from he to she, and good and bad. and show which words are strong on those vectors. See how this is plotted below!
spread(comparison,similarity) %>%
ggplot() +
geom_text() +
aes(x=`he - she`, y=`good - bad`, label=word)
model %>%
closest_to(list(~"man" - "woman", ~"good" - "bad"), n = 500, merge.method = "magnitude") %>%
# ebb: This is saying, make a vector showing the distance from he to she, and good and bad. and show which words are strong on those vectors. See how this is plotted below!
spread(comparison,similarity) %>%
ggplot() +
geom_text() +
aes(x=`man - woman`, y=`good - bad`, label=word)
model %>%
closest_to(list(~"she" - "he", ~"good" - "bad"), n = 500, merge.method = "magnitude") %>%
# ebb: This is saying, make a vector showing the distance from he to she, and good and bad. and show which words are strong on those vectors. See how this is plotted below!
spread(comparison,similarity) %>%
ggplot() +
geom_text() +
aes(x=`she - he`, y=`good - bad`, label=word)
# install.packages("abind")
# Read in Hansard topics with 19th century dates.
models = read_group(list.files(".",pattern = "^19[0-9]+"))
models[[3]] %>% nearest_to("navy")
# install.packages("abind")
# Read in Hansard topics with 19th century dates.
models = read_group(list.files(".",pattern = "^19[0-9]+"))
models[[3]] %>% nearest_to("awful")
# install.packages("abind")
# Read in Hansard topics with 19th century dates.
models = read_group(list.files(".",pattern = "^19[0-9]+"))
models[[2]] %>% nearest_to("navy")
# install.packages("abind")
# Read in Hansard topics with 19th century dates.
models = read_group(list.files(".",pattern = "^19[0-9]+"))
models[[1]] %>% nearest_to("navy")
getwd()
setwd("/Users/elisa/Documents/GitHub/machineLearning/")
getwd()
38+4
38mod7
38?7
6*7
paste("forty", "two")
answer = 42
answer > 30
answer == 40
answer === 40
tip = "don't panic"
tip
grepl(tip, pattern = "panic")
grepl(tip, pattern = "'")
grepl(tip, pattern = "'")
install.packages("dplyer")
install.packages("dplyr")
library(dplyr)
install.packages(c("tidytext","gutenbergr","ggplot2","stringr"))
library(tidytext)
library(gutenbergr)
library(ggplot2)
library(stringr)
knitr::opts_chunk$set(echo = TRUE)
#Load one library at a time:
library(dplyr)
library(tidytext)
library(gutenbergr)
library(ggplot2)
library(stringr)
#Advanced Move: load a few at a time:
lapply(c("tidytext","gutenbergr","ggplot2","stringr"),require, character.only = TRUE)
MacBethAct1Scene1 = c("ACT I
SCENE I. An open Place.
Thunder and Lightning. Enter three Witches.
FIRST WITCH.
When shall we three meet again?
In thunder, lightning, or in rain?
SECOND WITCH.
When the hurlyburly’s done,
When the battle’s lost and won.
THIRD WITCH.
That will be ere the set of sun.
FIRST WITCH.
Where the place?
SECOND WITCH.
Upon the heath.
THIRD WITCH.
There to meet with Macbeth.
FIRST WITCH.
I come, Graymalkin!
SECOND WITCH.
Paddock calls.
THIRD WITCH.
Anon.
ALL.
Fair is foul, and foul is fair:
Hover through the fog and filthy air.")
MacBethAct1Scene1
MacBethAct1Scene1 = unlist(strsplit(MacBethAct1Scene1,split="\n"))
Act1Scene1Lines_df = tibble(line = 1:38, text = MacBethAct1Scene1, act = 1, scene = 1)
MacBethAct1Scene1 = unlist(strsplit(MacBethAct1Scene1,split="\n"))
Act1Scene1Lines_df = tibble(line = 1:38, text = MacBethAct1Scene1, act = 1, scene = 1)
Act1Scene1Lines_df
unnest_tokens(Act1Scene1Lines_df,output = word,input = text, token = "words")
unnest_tokens(Act1Scene1Lines_df,output = word,input = text, token = "words")
Act1Scene1Lines_df %>%
unnest_tokens(       output = word,input = text, token = "words")
Act1Scene1Lines_df %>%
unnest_tokens(   output = sentence,input = text, token = "sentences")
unnest_tokens(     output = ngrams,input = text, token = "ngrams", n = 2) # token is a bigram
Act1Scene1Lines_df %>%
unnest_tokens(     output = ngrams,input = text, token = "ngrams", n = 2)
Act1Scene1Lines_df %>%
unnest_tokens(     output = ngrams,input = text, token = "ngrams", n = 5)
Act1Scene1Lines_df %>%
unnest_tokens(     output = ngrams,input = text, token = "ngrams", n = 3)
Act1Scene1Lines_df %>%
unnest_tokens(      output = witchy,input = text, token = "regex", pattern = "WITCH.")
library(gutenbergr)
Macbeth = gutenberg_download(1533)
acts = Macbeth %>%
unnest_tokens(      output = scenes,input = text, token = "regex", pattern = "ACT")
scenes = Macbeth %>%
unnest_tokens(      output = scenes,input = text, token = "regex", pattern = "SCENE")
scenes = Macbeth %>%
unnest_tokens(      output = scenes,input = text, token = "regex", pattern = "SCENE")
Macbeth %>%
unnest_tokens(      output = individualwords,input = text, token = "words")  %>%
count(individualwords,sort = TRUE)
Macbeth %>%
unnest_tokens(      output = individualwords,input = text, token = "words")  %>%
count(individualwords) %>%
subset(individualwords == "act")
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act ", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act (i|x|v|l|c|d|m)", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act [ixvlcdm)]", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act [ixvlcdm)]", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act [ixvlcdm]+", ngrams))
Macbeth %>%
+   unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
+   count(ngrams) %>%
+   filter(grepl("act [ixvlcdm]+", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act [ixvlcdm]", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act [ixvlcdm]+\b", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act [ixvlcdm]+", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act [ixvlcdm]\s", ngrams))
Macbeth %>%
unnest_tokens(      output = ngrams,input = text, token = "ngrams",n=2)  %>%
count(ngrams) %>%
filter(grepl("act [ixvlcdm]+\\b", ngrams))
Maggie_df <- data_frame(line = 1, text = Maggie)
Maggie = c("I ain't gonna work on Maggie's farm no more
No, I ain't gonna work on Maggie's farm no more
Well, I wake up in the morning, fold my hands and pray for rain
I got a head full of ideas that are drivin' me insane
It's a shame the way she makes me scrub the floor
I ain't gonna work on Maggie's farm no more
I ain't gonna work for Maggie's brother no more
No, I ain't gonna work for Maggie's brother no more
Well, he hands you a nickel, he hands you a dime
He asks you with a grin if you're havin' a good time
Then he fines you every time you slam the door
I ain't gonna work for Maggie's brother no more
I ain't gonna work for Maggie's pa no more
No, I ain't gonna work for Maggie's pa no more
Well, he puts his cigar out in your face just for kicks
His bedroom window, it is made out of bricks
The national guard stands around his door
Ah, I ain't gonna work for Maggie's pa no more
I ain't gonna work for Maggie's ma no more
No, I ain't gonna work for Maggie's ma no more
Well, she talks to all the servants about man and God and law
Everybody says, she's the brains behind pa
She's sixty-eight but she says she's fifty-four
I ain't gonna work for Maggie's ma no more
I ain't gonna work on Maggie's farm no more
I ain't gonna work on Maggie's farm no more
Well, I try my best to be just like I am
But everybody wants you to be just like them
They say sing while you slave and I just get bored
Ah, I ain't gonna work on Maggie's farm no more")
Maggie_df <- data_frame(line = 1, text = Maggie)
Maggie_df %>%
unnest_tokens(      output = words,input = text, token = "words")  %>%
count(words,sort=TRUE) %>%
mutate(words = reorder(words,n)) %>%
filter(n>3)%>%
# start the plotting part
ggplot(aes(words,n),size = 7) +   # this says that we are using data words and n
geom_col() +                      # this is the plot type
xlab(NULL) +                      # this turns off the x label since it makes things look messy
theme_minimal() +                 # style choice
coord_flip()                      # rotate the plot
Maggie_df <- data_frame(line = 1, text = Maggie)
Maggie = c("I ain't gonna work on Maggie's farm no more
+ No, I ain't gonna work on Maggie's farm no more
+ Well, I wake up in the morning, fold my hands and pray for rain
+ I got a head full of ideas that are drivin' me insane
+ It's a shame the way she makes me scrub the floor
+ I ain't gonna work on Maggie's farm no more
+ I ain't gonna work for Maggie's brother no more
+ No, I ain't gonna work for Maggie's brother no more
+ Well, he hands you a nickel, he hands you a dime
+ He asks you with a grin if you're havin' a good time
+ Then he fines you every time you slam the door
+ I ain't gonna work for Maggie's brother no more
+ I ain't gonna work for Maggie's pa no more
+ No, I ain't gonna work for Maggie's pa no more
+ Well, he puts his cigar out in your face just for kicks
+ His bedroom window, it is made out of bricks
+ The national guard stands around his door
+ Ah, I ain't gonna work for Maggie's pa no more
+ I ain't gonna work for Maggie's ma no more
+ No, I ain't gonna work for Maggie's ma no more
+ Well, she talks to all the servants about man and God and law
+ Everybody says, she's the brains behind pa
+ She's sixty-eight but she says she's fifty-four
+ I ain't gonna work for Maggie's ma no more
+ I ain't gonna work on Maggie's farm no more
+ I ain't gonna work on Maggie's farm no more
+ Well, I try my best to be just like I am
+ But everybody wants you to be just like them
+ They say sing while you slave and I just get bored
+ Ah, I ain't gonna work on Maggie's farm no more")
Maggie_df <- data_frame(line = 1, text = Maggie)
Maggie_df %>%
unnest_tokens(      output = words,input = text, token = "words")
count(words,sort=TRUE) %>%
unnest_tokens(      output = words,input = text, token = "words")  %>%
count(words,sort=TRUE)
unnest_tokens(      output = words,input = text, token = "words")  %>%
count(words,sort=TRUE)
Maggie_df %>%
unnest_tokens(      output = words,input = text, token = "words")  %>%
count(words,sort=TRUE)
Maggie_df %>%
unnest_tokens(      output = words,input = text, token = "words")  %>%
count(words,sort=TRUE) %>%
mutate(words = reorder(words,n))
Maggie_df %>%
unnest_tokens(      output = words,input = text, token = "words")  %>%
count(words,sort=TRUE) %>%
mutate(words = reorder(words,n)) %>%
filter(n>3)%>%
# start the plotting part
ggplot(aes(words,n),size = 7) +   # this says that we are using data words and n
geom_col() +                      # this is the plot type
xlab(NULL) +
Maggie_df %>%
unnest_tokens(      output = words,input = text, token = "words")  %>%
count(words,sort=TRUE) %>%
mutate(words = reorder(words,n)) %>%
filter(n>3)%>%
# start the plotting part
ggplot(aes(words,n),size = 7) +   # this says that we are using data words and n
geom_col() +                      # this is the plot type
xlab(NULL) +                      # this turns off the x label since it makes things look messy
theme_minimal() +                 # style choice
coord_flip()                      # rotate the plot
Maggie_df %>%
unnest_tokens(      output = words,input = text, token = "words")  %>%
count(words,sort=TRUE) %>%
mutate(words = reorder(words,n)) %>%
filter(n>3)%>%
# start the plotting part
ggplot(aes(words,n),size = 7) +   # this says that we are using data words and n
geom_col() +                      # this is the plot type
xlab(NULL) +                      # this turns off the x label since it makes things look messy
theme_minimal() +                 # style choice
coord_flip()                      # rotate the plot
gutenberg_works(author == "Austen, Jane")
gutenberg_works(author == "Austen")
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
tidy_books = JaneBooks %>%
group_by(title) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
JaneBooks = gutenberg_works(author == "Austen, Jane") %>%
gutenberg_download(meta_fields = "title")
JaneBooks = gutenberg_works(author == "Austen, Jane") %>%
gutenberg_download(meta_fields = "title")
tidy_books = JaneBooks %>%
group_by(title) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
knitr::opts_chunk$set(echo = TRUE)
tidy_books = JaneBooks %>%
group_by(title) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books = JaneBooks %>%
group_by(title) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
library(stringr)
library("tidyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
tidy_books = JaneBooks %>%
group_by(title) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
tidy_books %>%
filter(title == "Emma") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
jane_austen_nrc_full = tidy_books %>%
inner_join(get_sentiments("nrc")) %>%
count(title, index = linenumber %/% 80, sentiment)%>%
mutate(method = "NRC")
ggplot(jane_austen_nrc_full, aes(index, n,color = sentiment)) +
geom_line() +
facet_grid(~ sentiment)+
facet_wrap(~title, ncol = 2, scales = "free_x")  # split by title
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
tidy_books %>%
filter(title == "Emma") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
nrc_joy
tidy_books %>%
filter(title == "Emma") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
joywords = tidy_books %>%
filter(title == "Emma") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
View(joywords)
jane_austen_sentiment = tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(title, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
jane_austen_sentiment
library(ggplot2)
ggplot(jane_austen_sentiment,     # data to use
aes(index, sentiment, fill = title)) +   # variables: index[line number], sentiment, and colour each book individually
geom_col(show.legend = FALSE) +            # style
facet_wrap(~title, ncol = 2, scales = "free_x")  # colouring
jane_austen_sentiment = tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(title, chapter, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
library(ggplot2)
ggplot(jane_austen_sentiment,     # data to use
aes(chapter, sentiment, fill = title)) +   # variables: index[line number], sentiment, and colour each book individually
geom_col(show.legend = FALSE) +            # style
facet_wrap(~title, ncol = 2, scales = "free_x")  # colouring
jane_austen_afinn = tidy_books %>%
inner_join(get_sentiments("afinn")) %>%
group_by(title, index = linenumber %/% 80) %>%
summarise(sentiment = sum(score)) %>%
mutate(method = "AFINN")
ggplot(jane_austen_afinn,     # data to use
aes(index, sentiment, fill = title)) +   # variables: index[line number], sentiment, and colour each book individually
geom_col(show.legend = FALSE) +            # style
facet_wrap(~title, ncol = 2, scales = "free_x")  # split by title
jane_austen_nrc = tidy_books %>%
inner_join(get_sentiments("nrc")) %>%
filter(sentiment %in% c("positive", "negative"))%>%
mutate(method = "NRC") %>%
count(title, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(jane_austen_nrc,     # data to use
aes(index, sentiment, fill = title)) +   # variables: index[line number], sentiment, and colour each book individually
geom_col(show.legend = FALSE) +            # style
facet_wrap(~title, ncol = 2, scales = "free_x")  # split by title
JaneJustBooks = tidy_books %>%
inner_join(get_sentiments("nrc")) %>%
filter(!grepl("(Complete Project)|(Letters of Jane)", title))%>% #exclude the search items using !
filter(chapter==1)
JaneJustBooks %>%
count(title, sentiment)%>%
spread(sentiment,n)
chisq.test(JaneJustBooks$title,JaneJustBooks$sentiment)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(dplyr)
library(tidytext)
library(ggplot2)
library(stringr)
library(gutenbergr)
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(dplyr)
library(tidytext)
library(ggplot2)
library(stringr)
library(gutenbergr)
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
# Download HG Wells books from Gutenberg
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("tidyverse")
# Download HG Wells books from Gutenberg
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
# Download HG Wells books from Gutenberg
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
# Download HG Wells books from Gutenberg
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
library("gutenbergr", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
library(dplyr)
library(tidytext)
library(ggplot2)
library(stringr)
library(gutenbergr)
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
library(scales)
library(gmodels)
install.packages("gmodels")
# Download HG Wells books from Gutenberg
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
# Download HG Wells books from Gutenberg
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
